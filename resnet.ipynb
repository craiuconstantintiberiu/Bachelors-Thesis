{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "    Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from math import sin, cos, pi\n",
    "\n",
    "import tensorflow\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.layers import Conv2D, LeakyReLU, GlobalAveragePooling2D, Dropout, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process keypoints and resize them to correspond to images being 224x224"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "newX = 224\n",
    "newY = 224\n",
    "\n",
    "def getNewValueAfterResize(coordinate, originalSize, newLength=newX):\n",
    "    return newLength / int(originalSize) * int(coordinate)\n",
    "\n",
    "\n",
    "def getNewValueAfterResizeAsString(coordinate, originalSize, newLength=newX):\n",
    "    return str(getNewValueAfterResize(coordinate, originalSize, newLength))\n",
    "\n",
    "def writeAnnotationFile(original_file, new_file):\n",
    "    file1 = open(original_file, 'r')\n",
    "    lines = file1.readlines()\n",
    "    newlines = [\n",
    "        'left_acetabular_x,left_acetabular_y,left_femural_x,left_femural_y,right_acetabular_x,right_acetabular_y,right_femural_x,right_femural_y']\n",
    "    for i in range(0, len(lines), 4):\n",
    "        la = lines[i].split(\",\")\n",
    "        lf = lines[i + 1].split(\",\")\n",
    "        rf = lines[i + 2].split(\",\")\n",
    "        ra = lines[i + 3].split(\",\")\n",
    "        original_image_size_x = int(la[4])\n",
    "        original_image_size_y = int(la[5])\n",
    "        new_elem = getNewValueAfterResizeAsString(la[1], original_image_size_x) + ',' + getNewValueAfterResizeAsString(\n",
    "            la[2], original_image_size_y) + ',' + getNewValueAfterResizeAsString(lf[1],\n",
    "                                                                                 original_image_size_x) + ',' + getNewValueAfterResizeAsString(\n",
    "            lf[2], original_image_size_y) + ',' + \\\n",
    "                   getNewValueAfterResizeAsString(rf[1], original_image_size_x) + ',' + getNewValueAfterResizeAsString(\n",
    "            rf[2], original_image_size_y) + ',' + getNewValueAfterResizeAsString(ra[1], original_image_size_x) + ',' + getNewValueAfterResizeAsString(ra[2], original_image_size_y)\n",
    "        print(new_elem)\n",
    "        newlines.append(new_elem)\n",
    "    filetest = open(new_file, \"w\")\n",
    "    newText = '\\n'.join(newlines)\n",
    "    filetest.write(newText)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writeTest():\n",
    "    writeAnnotationFile('AnnotationsAllImages512/annotations_test.csv', \"newAnnotationsTest224Res.csv\")\n",
    "\n",
    "def writeTraining():\n",
    "    writeAnnotationFile('AnnotationsAllImages512/annotations_training.csv', \"newAnnotationsTraining224Res.csv\")\n",
    "\n",
    "def writeInternetTest():\n",
    "    writeAnnotationFile('InternetImages/labels_internet_test.csv', \"newAnnotationsTestInternet224Res.csv\")\n",
    "\n",
    "def writeInternetTraining():\n",
    "    writeAnnotationFile('InternetImages/labels_internet_training.csv', \"newAnnotationsTrainingInternet224Res.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writeTest()\n",
    "writeTraining()\n",
    "writeInternetTest()\n",
    "writeInternetTraining()\n",
    "training_annotations = pd.read_csv(\"newAnnotationsTraining224Res.csv\")\n",
    "test_annotations = pd.read_csv(\"newAnnotationsTest224Res.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load images from folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convertImage(img):\n",
    "    color = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    resize = cv2.resize(color, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    return np.reshape(resize, (224,224,1))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images = []\n",
    "    for f in os.listdir(directory):\n",
    "        images.append(convertImage(cv2.imread(os.path.join(directory,f))))\n",
    "    images = np.array(images)/255.\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_keypoints(keypoint_data):\n",
    "    keypoint_data_csv = pd.read_csv(keypoint_data)\n",
    "    keypoint_features = []\n",
    "    for idx, features in keypoint_data_csv.iterrows():\n",
    "        keypoint_features.append(features)\n",
    "    keypoint_features = np.array(keypoint_features, dtype=float)\n",
    "    return keypoint_features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images = np.concatenate((load_images('AnnotationsAllImages512/training'), load_images('InternetImages/train')))\n",
    "images = np.concatenate((load_images('AnnotationsAllImages512/training'), load_images('InternetImages/train')))\n",
    "train_keypoints = np.concatenate((load_keypoints('newAnnotationsTraining224Res.csv'), load_keypoints(\"newAnnotationsTrainingInternet224Res.csv\")))\n",
    "keypoints = np.concatenate((load_keypoints('newAnnotationsTraining224Res.csv'), load_keypoints(\"newAnnotationsTrainingInternet224Res.csv\")))\n",
    "test_images = np.concatenate((load_images('AnnotationsAllImages512/test'), load_images('InternetImages/test')))\n",
    "test_keypoints=np.concatenate((load_keypoints('newAnnotationsTest224Res.csv'), load_keypoints('newAnnotationsTestInternet224Res.csv')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_sample(image, keypoint, axis, title):\n",
    "\n",
    "    image = image.reshape(224,224)\n",
    "    axis.imshow(image, cmap='gray')\n",
    "    axis.scatter(keypoint[0::2], keypoint[1::2], c=[\"r\", \"b\", \"g\",\"m\"], marker='x', s=20)\n",
    "    plt.title(title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_samples_and_save_them_to_folder(images, keypoints, folder):\n",
    "    for i in range(len(images)):\n",
    "        print(i)\n",
    "        image=images[i]\n",
    "        image = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        image= np.reshape(image, (224, 224, 1))\n",
    "        keypoint=keypoints[i]\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        colors = itertools.cycle([\"r\", \"b\", \"g\",\"m\"])\n",
    "        keypoint_x=keypoint[0::2]\n",
    "        keypoint_y=keypoint[1::2]\n",
    "        for idx in range(4):\n",
    "            plt.scatter(keypoint_x[idx], keypoint_y[idx], color=next(colors), marker='x', s=20)\n",
    "        plt.savefig('./'+folder +\"/\"+ str(i) + \".png\")\n",
    "        plt.close()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rotation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rotate_augmentation(images, keypoints, rotation_angles):\n",
    "    rotated_images = []\n",
    "    rotated_keypoints = []\n",
    "    for angle in rotation_angles:\n",
    "        for angle in [angle, -angle]:\n",
    "            M = cv2.getRotationMatrix2D((112,112), angle, 1.)\n",
    "            angle_rad = -angle*pi/180.\n",
    "            for image in images:\n",
    "                rotated_image = cv2.warpAffine(image, M, (224,224), flags=cv2.INTER_CUBIC)\n",
    "                rotated_images.append(rotated_image)\n",
    "            for keypoint in keypoints:\n",
    "                rotated_keypoint = keypoint - 112.\n",
    "                for idx in range(0, len(rotated_keypoint), 2):\n",
    "                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n",
    "                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n",
    "                rotated_keypoint += 112.\n",
    "                rotated_keypoints.append(rotated_keypoint)\n",
    "\n",
    "    return np.reshape(rotated_images,(-1,224,224,1)), rotated_keypoints\n",
    "\n",
    "rotated_train_images, rotated_train_keypoints = rotate_augmentation(images, keypoints, aug_config.rotation_angles)\n",
    "train_images = np.concatenate((train_images, rotated_train_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))\n",
    "fig, axis = plt.subplots()\n",
    "plot_sample(rotated_train_images[19], rotated_train_keypoints[19], axis, \"Rotation Augmentation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Brightness alteration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def alter_brightness(images, keypoints):\n",
    "    altered_brightness_images = []\n",
    "    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)\n",
    "    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)\n",
    "    altered_brightness_images.extend(inc_brightness_images)\n",
    "    altered_brightness_images.extend(dec_brightness_images)\n",
    "    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n",
    "\n",
    "\n",
    "altered_brightness_images, altered_brightness_keypoints = alter_brightness(images, keypoints)\n",
    "train_images = np.concatenate((train_images, altered_brightness_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, altered_brightness_keypoints))\n",
    "fig, axis = plt.subplots()\n",
    "plot_sample(altered_brightness_images[19], altered_brightness_keypoints[19], axis, \"Alter Brightness Augmentation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shift_images(images, keypoints, pixel_shifts):\n",
    "    shifted_images = []\n",
    "    shifted_keypoints = []\n",
    "    for shift in pixel_shifts:\n",
    "        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n",
    "            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n",
    "            for image, keypoint in zip(images, keypoints):\n",
    "                shifted_image = cv2.warpAffine(image, M, (224,224), flags=cv2.INTER_CUBIC)\n",
    "                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n",
    "                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<224.0):\n",
    "                    shifted_images.append(shifted_image.reshape(224,224,1))\n",
    "                    shifted_keypoints.append(shifted_keypoint)\n",
    "    shifted_keypoints = np.clip(shifted_keypoints,0.0,224.0)\n",
    "    return shifted_images, shifted_keypoints\n",
    "\n",
    "shifted_train_images, shifted_train_keypoints = shift_images(images, keypoints, aug_config.pixel_shifts)\n",
    "train_images = np.concatenate((train_images, shifted_train_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))\n",
    "fig, axis = plt.subplots()\n",
    "plot_sample(shifted_train_images[8], shifted_train_keypoints[8], axis, \"Shift Augmentation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_noise(images):\n",
    "    noisy_images = []\n",
    "    for image in images:\n",
    "        noisy_image = cv2.add(image, 0.018*np.random.randn(224,224,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n",
    "        noisy_images.append(noisy_image.reshape(224,224,1))\n",
    "    return noisy_images\n",
    "\n",
    "noisy_train_images = add_noise(images)\n",
    "train_images = np.concatenate((train_images, noisy_train_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, keypoints))\n",
    "fig, axis = plt.subplots()\n",
    "plot_sample(noisy_train_images[8], keypoints[8], axis, \"Random Noise Augmentation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Horizontal flips"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flip_images(images, keypoints):\n",
    "    flipped_keypoints=[]\n",
    "    flipped_images = []\n",
    "    for image, keypoint in zip(images, keypoints):\n",
    "        flipped_keypoint = np.array([(224 - point) if idx%2==0 else point for idx,point in enumerate(keypoint)])\n",
    "        for idx in range(2):\n",
    "            flipped_keypoint[idx], flipped_keypoint[idx+6] = flipped_keypoint[idx+6], flipped_keypoint[idx]\n",
    "            flipped_keypoint[idx+2], flipped_keypoint[idx+4] = flipped_keypoint[idx+4], flipped_keypoint[idx+2]\n",
    "\n",
    "        flipped_image=cv2.flip(image, 1)\n",
    "        flipped_keypoints.append(flipped_keypoint)\n",
    "        flipped_images.append(flipped_image.reshape(224,224,1))\n",
    "    return flipped_images, flipped_keypoints\n",
    "\n",
    "flipped_images, flipped_keypoints = flip_images(images, keypoints)\n",
    "train_images = np.concatenate((train_images, flipped_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, flipped_keypoints))\n",
    "fig, axis = plt.subplots()\n",
    "plot_sample(flipped_images[8], flipped_keypoints[8], axis, \"Horizontal flip augmentation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.applications.resnet import ResNet50\n",
    "\n",
    "model = Sequential()\n",
    "pretrained_model = ResNet50(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "model.add(Conv2D(3, (1,1), padding='same', input_shape=(224,224,1)))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(pretrained_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training model with resnet layers frozen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "earlyStopping = EarlyStopping(monitor='loss', patience=10, mode='min')\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.004, momentum=0.03, nesterov=True)\n",
    "optAdam = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-15, mode='min', verbose=1)\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = str(now.strftime(\"%H:%M:%S\"))\n",
    "current_time=current_time.replace(\":\",\"-\")\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"current_time.h5\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min')\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "history = model.fit(train_images, train_keypoints, epochs=20, batch_size=4, callbacks=[earlyStopping, rlp], validation_data=(test_images, test_keypoints))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot model history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "df = pd.DataFrame(history.history)\n",
    "df[['loss', 'val_loss']].plot(ax=ax[0])\n",
    "df[['root_mean_squared_error', 'val_root_mean_squared_error']].plot(ax=ax[1])\n",
    "ax[0].set_title('MSE')\n",
    "ax[1].set_title('RMSE')\n",
    "fig.suptitle('Model Metrics', fontsize=18);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save test set predictions before fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict = model.predict(test_images)\n",
    "plot_samples_and_save_them_to_folder(test_images,predict,\"ResNetTestResults/BeforeFinetuning\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model Finetuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "modelWeightsFile='saveResnetFinetunedRound3.h5'\n",
    "model_chpt = ModelCheckpoint(filepath=modelWeightsFile,\n",
    "                                     monitor='val_loss',\n",
    "                                     verbose=1,\n",
    "                                     save_weights_only=True,\n",
    "                                     save_best_only=True)\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "earlyStopping = EarlyStopping(monitor='loss', patience=10, mode='min')\n",
    "optAdam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, min_lr=1e-15, mode='min', verbose=1)\n",
    "model.layers[2].trainable=True\n",
    "model.compile(optimizer=optAdam, loss='mean_squared_error', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "history = model.fit(train_images, train_keypoints, epochs=45, batch_size=4, callbacks=[earlyStopping, rlp, model_chpt], validation_data=(test_images, test_keypoints))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict = model.predict(test_images)\n",
    "plot_samples_and_save_them_to_folder(test_images,predict,\"ResNetTestResults/AfterFinetuning\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}