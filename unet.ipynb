{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (925392395.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Users\\ttibi\\AppData\\Local\\Temp\\ipykernel_25968\\925392395.py\"\u001B[1;36m, line \u001B[1;32m14\u001B[0m\n\u001B[1;33m    UpSampling2D\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "import keras.backend as K\n",
    "import keras.utils\n",
    "\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Activation, Add, Conv2D, Conv2DTranspose, concatenate, Cropping2D, MaxPooling2D, Reshape,UpSampling2D\n",
    "from keras.models import Input, Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Nkeypoints = 4\n",
    "W = 224\n",
    "H = 224\n",
    "\n",
    "train_images = []\n",
    "train_keypoints = []\n",
    "test_images = []\n",
    "test_keypoints = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, imgs, kps, batch_size=4, shuffle=True):\n",
    "        self.imgs = imgs\n",
    "        self.kps = kps\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.imgs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _gaussian(self, xL, yL, H, W, sigma=5):\n",
    "        channel = [math.exp(-((c - xL) ** 2 + (r - yL) ** 2) / (2 * sigma ** 2)) for r in range(H) for c in range(W)]\n",
    "        channel = np.array(channel, dtype=np.float32)\n",
    "        channel = np.reshape(channel, newshape=(H, W))\n",
    "\n",
    "        return channel\n",
    "\n",
    "    def _to_heatmap(self, keypoints, sigma=5):\n",
    "        img_hm = np.zeros(shape=(224, 224, 2), dtype=np.float32)\n",
    "\n",
    "        for i in range(0, 2):\n",
    "            x = keypoints[i * 2]\n",
    "            y = keypoints[1 + 2 * i]\n",
    "            channel_hm = self._gaussian(x, y, 224, 224, sigma)\n",
    "            img_hm[:, :, i] = channel_hm\n",
    "        img_hm = np.reshape(img_hm, newshape=(img_hm.shape[0] * img_hm.shape[1] * 2, 1))\n",
    "\n",
    "        return img_hm\n",
    "\n",
    "    def __data_generation(self, idxs):\n",
    "        x = []\n",
    "        y = []\n",
    "        for idx in idxs:\n",
    "            #print(idxs)\n",
    "            img = self.imgs[idx]\n",
    "            keypoints = self.kps[idx]\n",
    "            img_hm = self._convertToHM(img, keypoints)\n",
    "            x.append(img)\n",
    "            y.append(img_hm)\n",
    "        return np.array(x, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        return self.__data_generation(indexes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process keypoints and resize them to correspond to images being 224x224"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "newX = 224\n",
    "newY = 224\n",
    "\n",
    "\n",
    "def getNewValueAfterResize(coordinate, originalSize, newLength=newX):\n",
    "    return newLength / int(originalSize) * int(coordinate)\n",
    "\n",
    "\n",
    "def getNewValueAfterResizeAsString(coordinate, originalSize, newLength=newX):\n",
    "    return str(getNewValueAfterResize(coordinate, originalSize, newLength))\n",
    "\n",
    "\n",
    "def writeAnnotationFile(original_file, new_file):\n",
    "    file1 = open(original_file, 'r')\n",
    "    lines = file1.readlines()\n",
    "    newlines = [\n",
    "        'left_acetabular_x,left_acetabular_y,left_femural_x,left_femural_y,right_acetabular_x,right_acetabular_y,right_femural_x,right_femural_y']\n",
    "    for i in range(0, len(lines), 4):\n",
    "        la = lines[i].split(\",\")\n",
    "        lf = lines[i + 1].split(\",\")\n",
    "        rf = lines[i + 2].split(\",\")\n",
    "        ra = lines[i + 3].split(\",\")\n",
    "        original_image_size_x = int(la[4])\n",
    "        original_image_size_y = int(la[5])\n",
    "        new_elem = getNewValueAfterResizeAsString(la[1], original_image_size_x) + ',' + getNewValueAfterResizeAsString(\n",
    "            la[2], original_image_size_y) + ',' + getNewValueAfterResizeAsString(lf[1],\n",
    "                                                                                 original_image_size_x) + ',' + getNewValueAfterResizeAsString(\n",
    "            lf[2], original_image_size_y) + ',' +\n",
    "                   getNewValueAfterResizeAsString(rf[1], original_image_size_x) + ',' + getNewValueAfterResizeAsString(\n",
    "            rf[2], original_image_size_y) + ',' + getNewValueAfterResizeAsString(ra[1],\n",
    "                                                                                 original_image_size_x) + ',' + getNewValueAfterResizeAsString(\n",
    "            ra[2], original_image_size_y)\n",
    "        print(new_elem)\n",
    "        newlines.append(new_elem)\n",
    "    filetest = open(new_file, \"w\")\n",
    "    newText = '\\n'.join(newlines)\n",
    "    filetest.write(newText)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writeTest():\n",
    "    writeAnnotationFile('AnnotationsAllImages512/annotations_test.csv', \"newAnnotationsTest224Res.csv\")\n",
    "\n",
    "\n",
    "def writeTraining():\n",
    "    writeAnnotationFile('AnnotationsAllImages512/annotations_training.csv', \"newAnnotationsTraining224Res.csv\")\n",
    "\n",
    "\n",
    "def writeInternetTest():\n",
    "    writeAnnotationFile('InternetImages/labels_internet_test.csv', \"newAnnotationsTestInternet224Res.csv\")\n",
    "\n",
    "\n",
    "def writeInternetTraining():\n",
    "    writeAnnotationFile('InternetImages/labels_internet_training.csv', \"newAnnotationsTrainingInternet224Res.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writeTest()\n",
    "writeTraining()\n",
    "writeInternetTest()\n",
    "writeInternetTraining()\n",
    "training_annotations = pd.read_csv(\"newAnnotationsTraining224Res.csv\")\n",
    "test_annotations = pd.read_csv(\"newAnnotationsTest224Res.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load images from folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convertImage(img):\n",
    "    color = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    resize = cv2.resize(color, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    return np.reshape(resize, (224, 224, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images = []\n",
    "    for f in os.listdir(directory):\n",
    "        images.append(convertImage(cv2.imread(os.path.join(directory, f))))\n",
    "    images = np.array(images) / 255.\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_keypoints(keypoint_data):\n",
    "    keypoint_data_csv = pd.read_csv(keypoint_data)\n",
    "    keypoint_features = []\n",
    "    for idx, features in keypoint_data_csv.iterrows():\n",
    "        keypoint_features.append(features)\n",
    "    keypoint_features = np.array(keypoint_features, dtype=float)\n",
    "    return keypoint_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images = np.concatenate((load_images('AnnotationsAllImages512/training'), load_images('InternetImages/train')))\n",
    "images = np.concatenate((load_images('AnnotationsAllImages512/training'), load_images('InternetImages/train')))\n",
    "train_keypoints = np.concatenate(\n",
    "    (load_keypoints('newAnnotationsTraining224Res.csv'), load_keypoints(\"newAnnotationsTrainingInternet224Res.csv\")))\n",
    "keypoints = np.concatenate(\n",
    "    (load_keypoints('newAnnotationsTraining224Res.csv'), load_keypoints(\"newAnnotationsTrainingInternet224Res.csv\")))\n",
    "test_images = np.concatenate((load_images('AnnotationsAllImages512/test'), load_images('InternetImages/test')))\n",
    "test_keypoints = np.concatenate(\n",
    "    (load_keypoints('newAnnotationsTest224Res.csv'), load_keypoints('newAnnotationsTestInternet224Res.csv')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rotation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rotate_augmentation(images, keypoints, rotation_angles):\n",
    "    rotated_images = []\n",
    "    rotated_keypoints = []\n",
    "    for angle in rotation_angles:\n",
    "        for angle in [angle, -angle]:\n",
    "            M = cv2.getRotationMatrix2D((112, 112), angle, 1.)\n",
    "            angle_rad = -angle * pi / 180.\n",
    "            for image in images:\n",
    "                rotated_image = cv2.warpAffine(image, M, (224, 224), flags=cv2.INTER_CUBIC)\n",
    "                rotated_images.append(rotated_image)\n",
    "            for keypoint in keypoints:\n",
    "                rotated_keypoint = keypoint - 112.\n",
    "                for idx in range(0, len(rotated_keypoint), 2):\n",
    "                    rotated_keypoint[idx] = rotated_keypoint[idx] * cos(angle_rad) - rotated_keypoint[idx + 1] * sin(\n",
    "                        angle_rad)\n",
    "                    rotated_keypoint[idx + 1] = rotated_keypoint[idx] * sin(angle_rad) + rotated_keypoint[\n",
    "                        idx + 1] * cos(angle_rad)\n",
    "                rotated_keypoint += 112.\n",
    "                rotated_keypoints.append(rotated_keypoint)\n",
    "\n",
    "    return np.reshape(rotated_images, (-1, 224, 224, 1)), rotated_keypoints\n",
    "\n",
    "\n",
    "rotated_train_images, rotated_train_keypoints = rotate_augmentation(images, keypoints, aug_config.rotation_angles)\n",
    "train_images = np.concatenate((train_images, rotated_train_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Brightness alteration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def alter_brightness(images, keypoints):\n",
    "    altered_brightness_images = []\n",
    "    inc_brightness_images = np.clip(images * 1.2, 0.0, 1.0)\n",
    "    dec_brightness_images = np.clip(images * 0.6, 0.0, 1.0)\n",
    "    altered_brightness_images.extend(inc_brightness_images)\n",
    "    altered_brightness_images.extend(dec_brightness_images)\n",
    "    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n",
    "\n",
    "\n",
    "altered_brightness_images, altered_brightness_keypoints = alter_brightness(images, keypoints)\n",
    "train_images = np.concatenate((train_images, altered_brightness_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, altered_brightness_keypoints))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shift_images(images, keypoints, pixel_shifts):\n",
    "    shifted_images = []\n",
    "    shifted_keypoints = []\n",
    "    for shift in pixel_shifts:\n",
    "        for (shift_x, shift_y) in [(-shift, -shift), (-shift, shift), (shift, -shift), (shift, shift)]:\n",
    "            M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "            for image, keypoint in zip(images, keypoints):\n",
    "                shifted_image = cv2.warpAffine(image, M, (224, 224), flags=cv2.INTER_CUBIC)\n",
    "                shifted_keypoint = np.array(\n",
    "                    [(point + shift_x) if idx % 2 == 0 else (point + shift_y) for idx, point in enumerate(keypoint)])\n",
    "                if np.all(0.0 < shifted_keypoint) and np.all(shifted_keypoint < 224.0):\n",
    "                    shifted_images.append(shifted_image.reshape(224, 224, 1))\n",
    "                    shifted_keypoints.append(shifted_keypoint)\n",
    "    shifted_keypoints = np.clip(shifted_keypoints, 0.0, 224.0)\n",
    "    return shifted_images, shifted_keypoints\n",
    "\n",
    "\n",
    "shifted_train_images, shifted_train_keypoints = shift_images(images, keypoints, aug_config.pixel_shifts)\n",
    "train_images = np.concatenate((train_images, shifted_train_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_noise(images):\n",
    "    noisy_images = []\n",
    "    for image in images:\n",
    "        noisy_image = cv2.add(image, 0.018 * np.random.randn(224, 224,\n",
    "                                                             1))  # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]\n",
    "        noisy_images.append(noisy_image.reshape(224, 224, 1))\n",
    "    return noisy_images\n",
    "\n",
    "\n",
    "noisy_train_images = add_noise(images)\n",
    "train_images = np.concatenate((train_images, noisy_train_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, keypoints))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Horizontal flips"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flip_images(images, keypoints):\n",
    "    flipped_keypoints = []\n",
    "    flipped_images = []\n",
    "    for image, keypoint in zip(images, keypoints):\n",
    "        flipped_keypoint = np.array([(224 - point) if idx % 2 == 0 else point for idx, point in enumerate(keypoint)])\n",
    "        for idx in range(2):\n",
    "            flipped_keypoint[idx], flipped_keypoint[idx + 6] = flipped_keypoint[idx + 6], flipped_keypoint[idx]\n",
    "            flipped_keypoint[idx + 2], flipped_keypoint[idx + 4] = flipped_keypoint[idx + 4], flipped_keypoint[idx + 2]\n",
    "\n",
    "        flipped_image = cv2.flip(image, 1)\n",
    "        flipped_keypoints.append(flipped_keypoint)\n",
    "        flipped_images.append(flipped_image.reshape(224, 224, 1))\n",
    "    return flipped_images, flipped_keypoints\n",
    "\n",
    "\n",
    "flipped_images, flipped_keypoints = flip_images(images, keypoints)\n",
    "train_images = np.concatenate((train_images, flipped_images))\n",
    "train_keypoints = np.concatenate((train_keypoints, flipped_keypoints))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generators"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(train_images,\n",
    "                          train_keypoints,\n",
    "                          batch_size=4)\n",
    "\n",
    "val_gen = DataGenerator(test_images, test_keypoints, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "UNET Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25968\\3348124592.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m \u001B[0munet\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mUNET\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m224\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m224\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munet\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25968\\3348124592.py\u001B[0m in \u001B[0;36mUNET\u001B[1;34m(input_shape)\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m     \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_shape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"Input\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;31m# downsampling\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "def UNET(input_shape):\n",
    "    def downsample_block(x, block_num, n_filters, pooling_on=True):\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "        skip = x\n",
    "\n",
    "        if pooling_on is True:\n",
    "            x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')(x)\n",
    "\n",
    "        return x, skip\n",
    "\n",
    "    def upsample_block(x, skip, block_num, n_filters):\n",
    "        x = Conv2DTranspose(n_filters, kernel_size=(2, 2), strides=2, padding='valid', activation='relu')(x)\n",
    "        x = concatenate([x, skip], axis=-1)\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    input = Input(input_shape, name=\"Input\")\n",
    "\n",
    "    # downsampling\n",
    "    x, skip1 = downsample_block(input, 1, 64)\n",
    "    x, skip2 = downsample_block(x, 2, 128)\n",
    "    x, skip3 = downsample_block(x, 3, 256)\n",
    "    x, skip4 = downsample_block(x, 4, 512)\n",
    "    x, _ = downsample_block(x, 5, 1024, pooling_on=False)\n",
    "\n",
    "    # upsampling\n",
    "    x = upsample_block(x, skip4, 6, 512)\n",
    "    x = upsample_block(x, skip3, 7, 256)\n",
    "    x = upsample_block(x, skip2, 8, 128)\n",
    "    x = upsample_block(x, skip1, 9, 64)\n",
    "\n",
    "    output = Conv2D(4, kernel_size=(1, 1), strides=1, padding='valid', activation='linear')(x)\n",
    "    output = Reshape(target_shape=(224 * 224 * 4, 1))(output)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "unet = UNET(input_shape=(224, 224, 1))\n",
    "print(unet.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_model = ModelCheckpoint(filepath='UnetModel.h5', monitor='val_loss', verbose=1, save_weights_only=True,\n",
    "                             save_best_only=True)\n",
    "unet.compile(optimizer='adam', loss='mse', metrics=[RootMeanSquaredError()])\n",
    "rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-15, mode='min', verbose=1)\n",
    "history= unet.fit(x=train_gen, validation_data=val_gen, epochs=40, callbacks=[save_model])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find coordinates given mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_coordinates_for_mask(mask):\n",
    "    summ = np.sum(mask)\n",
    "    positions=np.zeros(224,224)\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            positions[i][j]=j\n",
    "    x_score_map = mask * positions / summ\n",
    "    y_score_map = mask * np.transpose(positions) / summ\n",
    "    keypoint_x = np.sum(x_score_map, axis=None)\n",
    "    keypoint_y = np.sum(y_score_map, axis=None)\n",
    "    return keypoint_x, keypoint_y\n",
    "\n",
    "def find_coordinates_for_prediction(masks):\n",
    "    preds = []\n",
    "    masks_for_every_keypoint = np.reshape(masks, newshape=(224, 224, 4))\n",
    "    for k in range(masks_for_every_keypoint.shape[-1]):\n",
    "        xpred, ypred = find_coordinates_for_mask(masks_for_every_keypoint[:, :, k])\n",
    "        preds.append(xpred)\n",
    "        preds.append(ypred)\n",
    "    return preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print keypoints"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "mulBy=2\n",
    "\n",
    "def save_keypoints_plots(batch_imgs, batch_labels,predictions, folder):\n",
    "    name=\"IndividualImg\"\n",
    "    for idx in range(len(batch_imgs)):\n",
    "        crtLabel=batch_labels[idx]\n",
    "        crtPred=predictions[idx]\n",
    "        img = batch_imgs[idx]\n",
    "        img = np.reshape(img, newshape=(224, 224))\n",
    "        img = cv2.resize(img, (224*mulBy, 224*mulBy))\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        colors = itertools.cycle([\"r\", \"b\", \"g\",\"m\"])\n",
    "\n",
    "        for i in range(4):\n",
    "            kpx = crtPred[i*2]*mulBy\n",
    "            kpy = crtPred[i*2+1]*mulBy\n",
    "            plt.scatter(kpx, kpy, color=next(colors), marker='x', s=2)\n",
    "\n",
    "        for i in range(4):\n",
    "            kpx = crtLabel[i*2]*mulBy\n",
    "            kpy = crtLabel[i*2+1]*mulBy\n",
    "            plt.scatter(kpx, kpy, color='c', marker='x', s=2)\n",
    "\n",
    "        plt.savefig('./'+folder +\"/\"+ name+str(idx) + \".png\", dpi=800)\n",
    "        plt.close()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RMS Error on validation set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images,_ = val_gen[0]\n",
    "predicted_keypoints = unet.predict_on_batch(images)\n",
    "\n",
    "for idx in range(1,len(val_gen)):\n",
    "    images,_ = val_gen[idx]\n",
    "    new_predicted_keypoints=unet.predict_on_batch(images)\n",
    "    keypoints=np.concatenate((predicted_keypoints, new_predicted_keypoints))\n",
    "\n",
    "rms_error =RootMeanSquaredError(test_keypoints, predicted_keypoints)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}